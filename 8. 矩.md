▶ 期望值作为随机变量关于分布的积分
▶ 高阶矩
▶ 密度函数形态的描述
▶ 一些使用矩的不等式

**举例**：

假设我们有一个公平的骰子，对应的随机变量 $X$ 表示掷骰子的结果，它服从离散均匀分布，取值为 ${1,2,3,4,5,6}$.

>[!caution] 回顾勒贝格积分
>
>勒贝格积分是在测度空间 $(\Omega, \mathcal{A}, \mu)$ 上定义的：
>-  $\Omega$ 是非空集合
>- $\mathcal{A}$ 是 $\Omega$ 上的 $\sigma$-代数
>- $\mu$ 是 $\mathcal{A}$ 上的测度
>
>对于可测函数 $f: X \rightarrow \mathbb{R}$，勒贝格积分表示为：$\int_{\Omega} fd\mu$
>
>投掷骰子例子中，$\mathbb{P}$ 为概率测度，随机变量 $X$ 为可测函数，积分形式变为：$\int Xd\mathbb{P}$
>
>在离散情况下，**勒贝格积分变为加权和形式**：$\int_{\Omega} X({\omega})d\mathbb{P}(\omega) = \sum_{\omega \in \Omega} X({\omega}) \cdot \mathbb{P}({\omega})$

>[!caution] 回顾概率分布
>给定随机变量 $X: \Omega \rightarrow \mathbb{R}$，$X$ 的概率分布（或推断测度）$P_X$ 定义为：
>- 对于任意可测集 $A \subset \mathbb{R}$，$\mathbb{P}_X(A) = \mathbb{P}(X^{-1}(A)) = \mathbb{P}({\omega \in \Omega : X(\omega) \in A})$
>
>在离散情况下，概率分布可以表示为：
>- $\mathbb{P}_X({x}) = \mathbb{P}({\omega \in \Omega : X(\omega) = x})$，对所有 $x \in X(\Omega)$
>
>投掷骰子例子中：
>- $P_X({i}) = \frac{1}{6}$ 对所有 $i \in {1,2,3,4,5,6}$


>[!note] 期望值
>若 $X:\Omega \to \mathbb{R}$ 是一个拟可积的实值随机变量，则：
>
>$\mathbb{E}(X) := \int X d\mathbb{P} = \int xd\mathbb{P}_X(x)$ 被称为 X 的期望值

- **$X$**：随机变量，是从样本空间 $\Omega$ 到实数集 $\mathbb{R}$ 的可测函数
- **$\Omega$**：样本空间，包含所有可能的基本结果
- **$\mathbb{P}$**：原始概率空间上的概率测度，定义在 $\Omega$ 上的事件集合上
- **$\mathbb{P}_X$**：随机变量 $X$ 的分布，由 $X$ 诱导的概率测度
- **$x$**：实数值，**是 $X$ 的可能取值**，是积分中的积分变量
- **$\int X d\mathbb{P}$**：随机变量 $X$ 关于概率测度 $\mathbb{P}$ 的积分（在样本空间上积分）
- **$\int xd\mathbb{P}_X(x)$**：变量 $x$ 关于概率分布 $\mathbb{P}_X$ 的积分（在实数集上积分）


- 第一个积分表示 **随机变量** X 关于 **概率测度** $\mathbb{P}$ 的积分
- 第二个积分表示 **自变量** x 关于 **X 的分布** $\mathbb{P}_X$ 的积分
- "**拟可积**"指的是随机变量的正部分或负部分的积分至少有一个是有限的

- $\Omega = {\omega_1, \omega_2, \omega_3, \omega_4, \omega_5, \omega_6}$，对应六个面朝上的结果
- $X(\omega_i) = i$ 表示第 $i$ 面朝上对应的数字
- $\mathbb{P}({\omega_i}) = \frac{1}{6}$ 表示每个结果的概率相等
- $\mathbb{P}_X({1}) = \mathbb{P}_X({2}) = ... = \mathbb{P}_X({6}) = \frac{1}{6}$  -- **在样本空间中，所有被 $X$ 映射为 6 的基本事件的概率总和是多少？**
- $E(X) = \int Xd\mathbb{P} = \sum_{i=1}^6 X({w_i}) \cdot \mathbb{P}({w_i}) = \sum_{i=1}^6 i \cdot \frac{1}{6} = 3.5$
- $E(X) = \int xd\mathbb{P}_X(x) = \sum_{i=1}^6 x \cdot \mathbb{P}_X({x}) = \sum_{i=1}^6 x \cdot \frac{1}{6} = 3.5$

>[!bug] 变量变换公式（推导公式）
>设 $X : \Omega \to \mathbb{R}^n$ 是一个 n 维实值随机变量，且 $f:\mathbb{R}^n \to \mathbb{R}$ 是一个可测函数，使得复合函数 $f \circ X : \Omega \to \mathbb{R}$ 是可积的，那么：
>
>$\int gd\mathbb{P}_X = \int g \circ X d\mathbb{P}$


>[!important] $d\mathbb{P}$ 和 $d\mathbb{P}_X$ 的区别
>
>- $d\mathbb{P}$：表示在原始概率空间 $\Omega,\mathcal{F},\mathbb{P}$ 上的概率测度的微元
>- $d\mathbb{P}_X$：表示随机变量 $X$ 诱导的概率测度的微元。如果 $X$ 是从概率空间到可测空间的可测映射，那么 $\mathbb{P}_X$ 是 $X$ 在可测空间上诱导的概率分布，$\mathbb{P}_X(\mathcal{A}) = P(X \in \mathcal{A})$
>
>简单来说，$d\mathbb{P}$ 是在原始样本空间上的，而 $d\mathbb{P}_X$ 是在随机变量 $X$ 的值空间上的。这个区别在处理**随机变量的变换**、**Radon-Nikodym 导数**以及**条件期望**等问题时特别重要。

>[!important] R-N导数与 $d\mathbb{P}$ 的关系
>
>- 当**两个概率测度**之间存在**绝对连续关系**时，**R-N导数** 提供了它们之间的**精确联系**。
>
>- 如果**概率测度 $\mathbb{Q}$ **相对于 **$\mathbb{P}$** 是绝对连续的 (记为 $\mathbb{Q} << \mathbb{P}$)，则存在一个非负可测函数 $f$，使得对任意可测集 $A$，有：$\mathbb{Q}(A) = \int_A f d\mathbb{P}$，这个可测函数 $f$ 就是 **R-N导数**，记为 $d\mathbb{Q}/d\mathbb{P}$
>
>- 如果 $\mathbb{P} << \mu$，其中 $\mu$ 是某个参考测度，例如 Lebesgue测度，则 $d\mathbb{P}_X/d\mu$ 就是 $X$ 的概率密度函数

这个定理表明了**随机变量变换后**的积分计算方法，即:

- 左侧是函数 $g$ 关于 $X$ 的分布 $P_X$ 的积分
- 右侧是复合函数 $g \circ X$ 关于原始概率测度 $P$ 的积分

这是概率论中的一个重要公式，**用于计算随机变量函数的期望值**。它相当于概率论中的"变量替换公式"，**是从一个测度空间到另一个测度空间的积分转换方法**。

**举例**：

假设我们有一个随机变量 $X$ 服从标准正态分布 $N(0,1)$，我们想计算 $X^2$ 的期望。

我们可以设 $f(x) = x^2$，那么 $f(X) = X^2$。

**方法1**：使用定理中的右侧，在原始空间上积分

$\mathbb{E}[X^2] = \int (f \circ X)d\mathbb{P}(\omega) = \int X^2(\omega)d\mathbb{P}(\omega) = 1$（计算过程略 ... 因为还没有学到，很复杂）

**方法1**：使用定理中的左侧，直接在 $X$ 的分布上积分

$\mathbb{E}[X^2] = \int f(x)d\mathbb{P}_X(x)$

**因为** $\mathbb{P}_X(x) = \int f_X(x)dx$，所以 $d\mathbb{P}_X(x) = f_X(x)$，**所以**

$\mathbb{E}[X^2] = \int f(x)d\mathbb{P}_X(x) = \int x^2 \cdot \frac{1}{\sqrt{2\pi}}exp(-\frac{x^2}{2}) dx$

综上，$\mathbb{E}(X^2) = \int f \circ X d\mathbb{P} = \int fd\mathbb{P}_X = \int x^2 \cdot \frac{1}{\sqrt{2\pi}}exp(-\frac{x^2}{2}) dx$

>[!caution] 分部积分公式
>$\int udv = uv - \int vdu$

令 ：
- $u = x$
- $\phi(x) = \frac{1}{\sqrt{2\pi}}exp(-\frac{x^2}{2}) dx$ 
- $dv = x\phi(x)dx$

对 $\phi(x)$ 进行求导，得到 $\phi'(x) = -x\phi(x)$，则 $dv = -\phi'(x)dx$，得到 $v = -\phi(x)$

$\int x^2\phi(x)dx = x \cdot (-\phi(x)) - \int (-\phi(x))dx$ = 0 + 1(**正态分布归一性**) = 1

**复习知识点**：

- **分部积分公式**
- **被积函数 $f(x)$ 的原函数 $F(x)$ 关系是 $F'(x) = f(x)$**


在概率论中，当我们有一个随机变量 $X$ 和一个函数 $g$，我们经常需要计算 $g(X)$的期望值，因此，对于具有密度函数的随机变量，函数 $g(X)$ 的期望值：

- 密度函数：$f_X$
- 期望值：$\mathbb{E}(g(X)) = \int gd(f_X \odot \mu) = \int gf_Xd\mu$
- 例如，随机变量 X 是一个标准正态分布，$f_X$ 是标准正态分布的密度函数，而 $g(x) = x^2$ 
- 特殊情况：

	- **对于离散随机变量**，$\mu = \mu_Z$ 且 T（随机变量 X 的支撑集），$\mathbb{E}(g(X)) = \sum_{x \in T} g(x)f_X(x)$
	
	- **对于连续随机变量**，其密度函数 $f_X$ 是黎曼可积时，函数 $g(X)$ 的期望值可以通过对 $g(x)$ 与密度函数 $f_X(x)$的乘积在整个实数轴上进行积分来计算： $\mathbb{E}(g(X)) = \int_{-\infty}^{\infty} g(x)f_X(x)dx$

## 期望的性质

勒贝格积分的所有性质都可以直接应用到期望值上：

- 线性性质：

	- $\mathbb{E}(aX + b) = a\mathbb{E}(X) + b$
	- $\mathbb{E}(\sum_{i = 1}^nX_i) = \sum_{i = 1}^n \mathbb{E}(X_i)$

- 单调性质：

	- 如果 $X \leq Y$，则 $\mathbb{E}(X) \leq \mathbb{E}(Y)$

对于单调递增的**随机变量序列** $(X_n)_{n \in \mathbb{N}}$：$lim_{n \to \infty} \mathbb{E}(X_n) = \mathbb{E}(lim_{n \to \infty}X_n)$

>[!note] 单调递增的随机变量序列
>
>一个随机变量序列 $X_1, X_2, X_3,...$ 满足 $X_1 \leq X_2 \leq X_3 \leq ...$ (几乎处处)，也就是说，对于几乎所有的样本点 $\omega$，序列值满足 $X_1(\omega) \leq X_2(\omega) \leq X_3(\omega) \leq ...$
>

例子：我们投掷两次公平硬币：

- 设 X = 1 如果第一次投掷是正面，否则为 0
- 设 Y 是两次投掷中出现正面的次数

显然 X 和 Y 是随机依赖的！但是，$\mathbb{E}(X + Y) = \mathbb{E}(X) + \mathbb{E}(Y) = 0.5 + 1 = 1.5$

让我们分析可能的情况：

1. 第一次投掷为正面，第二次为正面：X = 1, Y = 2，因此 X + Y = 3
2. 第一次投掷为正面，第二次为反面：X = 1, Y = 1，因此 X + Y = 2
3. 第一次投掷为反面，第二次为正面：X = 0, Y = 1，因此 X + Y = 1
4. 第一次投掷为反面，第二次为反面：X = 0, Y = 0，因此 X + Y = 0

**这个例子中，强调期望值的线性性质 $\mathbb{E}(X + Y) = \mathbb{E}(X) + \mathbb{E}(Y)$ 适用于任何随机变量，无论它们是否独立**

**该例子通过一个简单的硬币投掷实验，故意构造了两个明显相依（非独立）的随机变量 X 和 Y，然后验证期望值的线性性质仍然成立：**

**这种性质在实际应用中非常有用，因为在许多情况下，我们需要计算相依随机变量和的期望，而这个性质允许我们将计算分解为单个随机变量期望的计算，即使这些随机变量不是独立的。**

## 伯努利分布的密度函数

设 $X \sim B(1,p)$ 的概率密度函数为 $f(x) = p^x \cdot (1-p)^{1-x} \cdot  I_{\{0,1\}}(x)$，那么，期望值可以通过以下方式计算：

$\mathbb{E}(X) = \int X d\mathbb{P} = \int xd\mathbb{P}_X(x) = \int xd(f_X \odot \mu_Z)(x) = \int xf_X(x)d\mu_Z(x) = \sum_{x \in \{0,1\}}x\cdot f_X(x) = 1 \cdot p + 0 \cdot (1-p) = p$
- **密度函数乘以指示函数意义：确保密度函数只在 $x = 0$ 和 $x = 1$ 时才有意义**
- 期望值公式：$\mathbb{E}(X) = \int X d\mathbb{P} = \int xd\mathbb{P}_X(x)$
- 概率测度分解：$= \int xd(f_X \odot \mu_Z)(x)$，$f_X$ 是密度函数，测度 $\mu_Z$ 是计数测度（离散变量），**根据 $R-N$ 定理，概率测度 $\mathbb{P}_X$ 可以找到一个函数 $f_X$ 和一个基础测度 $\mu_Z$，使得** $\mathbb{P}_X = f_X \odot \mu$，可以简单理解为**给测度一个"加权“**
- 积分变形：$= \int xf_X(x)d\mu_Z(x)$
- 积分号转为求和（离散变量）：$\sum_{x \in \{0,1\}}x\cdot f_X(x)$
- 计算：$= 1 \cdot p + 0 \cdot (1-p) = p$
	- 当 $x = 1$，概率密度 $f(x)$ 为 $p$
	- 当 $x = 0$，概率密度 $f(x)$ 为 $1 - p$

## 二项分布的密度函数

设 $X \sim B(n,p)$ 的概率密度函数为 $f(x) = C_n^x \cdot p^x(1-p)^{1-x}\cdot I_{0,...,n}(x)$，那么，期望值可以通过以下方式计算：

$\mathbb{E}(X) = \sum_{x=0}^n x\cdot C_n^x \cdot p^x(1-p)^{1-x} = np$

## 指数分布的密度函数

设 $X \sim Exp(\lambda)$ 的概率密度函数为 $f(x) = \lambda \cdot exp(-\lambda x) \cdot I_{\mathbb{R}^+}(x)$，那么，期望值可以通过以下方式计算：

$\mathbb{E}(X) = \frac{1}{\lambda}$

## 圣彼得堡悖论

在一个需要支付参与费用的赌博游戏中，一枚公平的硬币被投掷，直到第一次出现"正面"为止（几何分布）。

如果经过 x 次投掷才获胜，总共可以赢得 $2^{x-1}$欧元。对于参与这个游戏，你愿意支付多少金额？

设X为随机变量"投掷次数"。第一次在第x次硬币投掷中出现"正面"的概率是：$P(X = x) = (1/2)^x$

预期收益是：$\mathbb{E}(2^{X-1}) = \sum_{x=1}^{\infty}\mathbb{P}(X=x) \cdot 2^x = \sum_{x=1}^{\infty}\frac{1}{2} = \infty$

▶ 因此，预期收益是无限大的！  
▶ 从纯理性角度来看，你会接受无限大的赌注吗？？

这就产生了悖论：

- **从纯数学期望角度看，游戏的价值是无限的，理性人应该愿意支付任意高的价格参与**
- 但实际上，大多数人只愿意支付一个相对较小的金额（可能只有几欧元）

这种理论与实际行为的差异正是圣彼得堡悖论的核心，**它挑战了期望值理论在决策中的适用性，并促使人们思考风险态度、边际效用递减等因素在决策过程中的重要性。**

## 柯西分布

设 $X:\Omega \to \mathbb{R}$ 是具有连续密度函数的随机变量，$f(x) = \frac{1}{\pi (1+x^2)}$

那么 $X$ 被称为 柯西分布。

![[1749147072153.png]]

- 这是一个对称的钟形曲线
- **支撑集**：整个实数轴 (-∞, ∞)
- **期望值**：不存在有限的期望值，柯西分布的期望值不是无穷大，而是不存在（积分不收敛）
- **方差**：不存在

**提醒我们并非所有随机变量都具有期望值！！**

## 矩

**描述随机变量绝对值的分布特征**

设X是一个可积的随机变量，且 $n \in ℕ$，使得 $X^n$ 是准可积的，那么定义：

- $m_n(X) = \mathbb{E}(X^n)$ - n 阶矩
- $m_{(n)}(X) = \mathbb{E}(|X|^n)$ - n 阶绝对矩
- $m_n^0(X) = \mathbb{E}((X - \mathbb{E}(X))^n)$ - $X$ 的 $n$ 阶中心矩

- 一阶矩：$m_1(X) = \mathbb{E}(X)$
- 一阶中心矩：$m_1^0(X) = \mathbb{E}(X - \mathbb{E}(X))$
- 二阶中心矩：$m_n^2(X) = Var(X)$（方差）

## 随机变量的方差

若 $X$ 是一个随机变量，且 $\mathbb{E}(|X|) < \infty$，则：$Var(X) := \mathbb{E}((X - \mathbb{E}(X))^2)$，称为 $X$ 的方差。

### 平移公式

方差：$Var(X) := \mathbb{E}((X - \mathbb{E}(X))^2) = \mathbb{E}(X^2) - \mathbb{E}(X)^2$

### 方差的意义

1. **分散性度量**：方差越大，随机变量的值越分散，越偏离均值
2. **风险度量**：在金融和风险管理中，方差常用作风险的度量
3. **统计推断**：方差是许多统计方法的基础，如假设检验、区间估计等
4. **分布特征**：不同的概率分布有不同的方差特性

### 方差积分计算

▶ 连续随机变量：$Var(X) = \int(x - E(X))^2f_X(x)dx$

▶ 离散随机变量：$Var(X) = \sum_{x \in T}(x - E(X))^2f_X(x)$

### 线性变换

设 $Y = a \cdot X + b$ ，则 $Var(Y) = a^2Var(X)$

这个性质描述了随机变量经过线性变换后方差的变化规律：

1. **比例变换**：当随机变量X乘以常数a时，其方差会乘以a²
    
    - 如果 $a > 1$，方差增大（分散程度增加）
    - 如果 $0 < a < 1$，方差减小（分散程度减少）
    - 如果 $a < 0$，方差仍然乘以 $a^2$（只依赖于幅度，不依赖于方向）
    
2. **加法常数**：常数项b不影响方差
    
    - 加上或减去常数只会平移整个分布，不改变分散程度

### 方差与零测集

方差总是大于等于0，即 $Var(X) >= 0$。

$Var(X) = 0 \Rightarrow \{\omega \in \Omega | (X(\omega) - \mathbb{E}(X))^2\} > 0$ 是 $\mathbb{P}$ 零测集（概率为零的集合）

$\Rightarrow X = \mathbb{E}(X)$ $\mathbb{P}$ - 几乎处处

或者说：$X \sim \delta_{\mathbb{E}(X)}$  即 $X$ 的分布是 $\mathbb{E}(X)$ 处的狄拉克测度。

### 伯努利分布方差

设 $X \sin B(1,p)$

$Var(X) = \int (X - \mathbb{E}(X))^2d\mathbb{P} = \sum_{x \in T} x^2 \cdot f_X(x) - p^2 = 1^2 \cdot p + 0^2 \cdot (1 - p) - p^2 = p(1-p)$

因为伯努利分布是离散随机变量，因此：

- $Var(X) = \sum_{x \in T}(x - E(X))^2f_X(x)$
- $= \sum_{x \in T} \cdot (x^2 - 2x\mathbb{E}(X) + \mathbb{E}^2(X)) \cdot f_X(x)$
- $= \sum_{x \in T} x^2 \cdot f_X(x) - 2\mathbb{E}(X)\sum_{x \in T} x \cdot f_X(x) + \mathbb{E}(X)^2 \cdot \sum_{x \in T} f_X(x)$
- $=\sum_{x \in T} x^2 \cdot f_X(x) - 2\mathbb{E}(X) \cdot \mathbb{E}(X) + \mathbb{E}(X)^2 \cdot 1$
- $=\sum_{x \in T} x^2 \cdot f_X(x) - \mathbb{E}(X)^2$
- 对于伯努利分布，$\mathbb{E}(X) = p$，因此
- $=\sum_{x \in T} x^2 \cdot f_X(x) - p^2$
- 对于伯努利分布，$f_X(1) = p, f_X(0) = 1 - p$
- $=\sum_{x \in \{0,1\}} x^2 \cdot f_X(x) - p^2$
- $= 1^2 \cdot p - 0^2 \cdot (1-p)$

### 二项分布方差

设 $X \sin B(n,p)$

$Var(X) = ... np(1-p)$

### 指数分布方差

设 $X \sin Exp(\lambda)$

$\mathbb{E}(X^2) = \frac{2}{\lambda^2}$

$Var(X^2) = \frac{1}{\lambda^2}$

### 连续均匀分布方差

$\mathbb{E}(X) = \frac{a+b}{2}$

$Var(X) = \frac{(b-a)^2}{12}$

## 偏度

偏度是描述概率分布形状的一个重要特征，它衡量分布的不对称程度

$\gamma(X) := \frac{m_3^0(X)}{m_2^0(X)^{\frac{3}{2}}} = \frac{\mathbb{E}((X - E(X))^3)}{\sqrt{Var(x)}^3}$

- **正偏度 (γ > 0)**：
    
    - 分布右侧尾部较长
    - 大多数数值集中在左侧
    - 均值通常大于中位数
    
- **负偏度 (γ < 0)**：
    
    - 分布左侧尾部较长
    - 大多数数值集中在右侧
    - 均值通常小于中位数
    
- **零偏度 (γ = 0)**：
    
    - 分布关于均值对称
    - 正态分布的偏度为0

偏度公式的分母是标准差的三次方，这样做是为了使偏度成为一个无量纲量，便于不同分布之间的比较。

对于常见分布的偏度：

1. **正态分布**：γ = 0（完全对称）
2. **指数分布**：γ = 2（强烈右偏）
3. **均匀分布**：γ = 0（对称）
4. **对数正态分布**：γ > 0（右偏）
5. **二项分布**：
    - 当 p = 0.5 时，γ = 0（对称）
    - 当 p < 0.5 时，γ > 0（右偏）
    - 当 p > 0.5 时，γ < 0（左偏）

### 对数正态分布

对数正态分布是右偏的（rechtschief）或称为左陡峭的（linkssteil）

$X \sim LN(\mu, \sigma^2)$

- $\mu$ - 位置参数
- $\sigma^2 \in \mathbb{R}^+$ 是尺度参数
- $I_{\mathbb{R}^+}(x)$ 是指示函数，表示密度函数仅在正实数上有定义

$ln(X) \sim N(\mu, \sigma^2)$


![[1749215857812.png]]

## 拱度

拱度是描述概率分布"尖峰性"和"尾部厚度"的一个统计量，它衡量分布的集中程度和尾部的极端值情况：

**定义**：设 $X^4$ 拟可积，那么：$K(X) := \frac{m_4^0(X)}{(m_2^0(X))^2}$ 称为 $X$ 的拱度。

1. **高峰度 (K > 3)**：
    
    - 分布的中心更加尖锐
    - 尾部更厚（即出现极端值的概率更高）
    - 被称为"尖峰分布"(leptokurtic)
    
2. **低峰度 (K < 3)**：
    
    - 分布的中心更加平缓
    - 尾部更薄
    - 被称为"平峰分布"(platykurtic)
    
3. **标准正态分布的峰度为 3**：
    
    - 常用作参考基准
    - 在某些文献中会定义"超额峰度"(excess kurtosis) = K - 3


![[1749221159473.png]]

## 拉普拉斯分布

**定义**：具有连续密度的随机变量 $X$，其密度函数为 $f(x) = \frac{1}{2\sigma}exp(-\frac{|x - \mu|}{\sigma})$ 称为称为拉普拉斯分布。

▶ $X \sim \text{Laplace}(\mu, \sigma) \Rightarrow K(X) = 6$  
▶ $X \sim \text{N}(\mu, \sigma^2) \Rightarrow K(X) = 3$  
▶ $X \sim \text{U}(a, b) \Rightarrow K(X) = 1.8$

## 对称分布

设 $\mathbb{P}$ 是 $(\mathbb{R},\mathcal{B})$ 上的分布，

**定义**：$\mathbb{P}$ 称为关于 $a \in \mathbb{R}$ 对称的，如果 $\mathbb{P}((-\infty,a - x]) = \mathbb{P}([a + x, \infty)))$

**定理**：设 $\mathbb{P}$ 是 $(\mathbb{R},\mathcal{B})$ 上关于 $a$ 对称的分布，$X \sim \mathbb{P}_X = \mathbb{P}$ 且 $g$ 是可积函数，则：

1. $\int g d\mathbb{P}_X = \int g(x) d\mathbb{P}_X(x) = \int g(2a-x) 

	当你遇到关于对称分布的积分、期望、方差等问题时，这个定理可以让你把 $g(x)$ 换成 $g(2a-x)$，有时可以简化运算

2. d\mathbb{P}_X(x)$
3. $m_1(X) = a$
4. $m_{2n+1}^0(X) = 0 \quad \forall n \in \mathbb{N}$
5. $a$ 是 $X$ 的中位数

## 马尔可夫和切比雪夫不等式

这是**概率的上界估计**，用于衡量随机变量“偏离中心”的概率有多大。

设 $X: \Omega \to \mathbb{R}$ 是一个实值随机变量，则对于每个 $\epsilon > 0$，有：

$\mathbb{P}(|X| > \epsilon)$ <= $\frac{1}{\epsilon^n} \int |X| \cdot I_{\{|X| > \epsilon\}}d\mathbb{P}$ 
         <= $\frac{1}{\epsilon^n} \mathbb{E}(|X|^n)$


$n$ 是正整数，通常 $n=1$ 得到 Markov不等式，$n=2$ 时可以推出 Chebyshev 不等式。

- **马尔可夫不等式**（n = 1)： $\mathbb{P}(|X| >= \epsilon) <= \frac{1}{\epsilon} \cdot \mathbb{E}(|X|)$
- **切比雪夫不等式**（n = 2)：
	- $\mathbb{P}(|X| >= \epsilon) <= \frac{1}{\epsilon^2} \cdot \mathbb{E}(X^2)$
	- $\mathbb{P}(|X - E(X)| >= \epsilon) <= \frac{E((X - E(X))^2)}{\epsilon^2} = \frac{Var(X)}{\epsilon^2}$
### 用处

- 这是**尾概率估计**的基本工具，广泛用于概率论、数理统计、随机过程等领域。
- 可用于证明大数定律、中心极限定理等重要结论的步骤。

## Jensen不等式

对于一个凸函数 $f(x)$，有：....


## 范数

**定义**：设 $f : \Omega \to \mathbb{R}$ 是在测度空间 $(\Omega, \mathcal{F}, \mu)$ 上 $\mathcal{F}-\mathcal{B}$ 可测的函数，则：

$\|f\|_p := (\int |f|^pd\mu)^{\frac{1}{p}} \in [0,\infty)$ 称为 $f$ 的 **p-范数**

**对随机变量 $X$，$|X|_p$ 就是 $X$ 的 $p$ 阶绝对矩的 $p$ 次方根**，即：$\mathbb{E}(|X|^p) = \|X\|_p^p$

当 $p=2$ 时，就是常见的平方均值根（均方根）

- **$p$-范数**度量了函数或随机变量在 $L^p$ 空间中的“长度”或“大小”。
- 在概率论中，$|X|_p$ 表示 $X$ 的 $p$ 阶绝对矩的 $p$ 次方根，是衡量随机变量分布发散程度的重要指标

**定义**：对于 $p \geq 1$，$L^p$ 空间定义为：

$L^p := L^p(\Omega,\mathcal{F},\mu) := \{f|f:\Omega \to \mathbb{R}, f 是 \mathcal{F}-\mathcal{B}可测的，\|f\|_p \le \infty\}$

