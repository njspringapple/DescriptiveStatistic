

#### 1. 协方差（Kovarianz）与相关系数  

##### 1.1 定义

协方差用于**衡量** **两个度量特征** 之间 **线性关系** 的强度和方向的指标：

- 数据 $(x_i,y_i), i = 1,...,n$
- $S_{xy} = \frac{1}{n-1} \Sigma_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})$

当计算 $S_{xx}$ 时候，得到的是 x 的方差 $s_{xx} = s_x^2$ （单随机变量的协方差等于方差）

- **反映关联方向**：
	- **正协方差**：说明两个变量正向线性相关，即当一个变量的值大于其均值时，另一个变量的值也倾向于大于其均值（反之亦然）
	- **负协方差**：说明两个变量呈现**反向线性关联**，即当一个变量的值大于其均值时，另一个变量的值倾向于小于其均值（反之亦然）
	- **零协方差**：说明两个变量**不存在线性关联**，但需注意：这并不意味着它们完全无关（可能存在非线性关系，如二次关系）
- **反应关联强度**：
	协方差的**绝对值越大**，理论上表明两个变量的线性关联程度越强

##### 1.2 **几何直观解释（Geometrische Intuition）：**

考虑一组数据点 $(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)$，首先将其 “**中心化**”：

- 计算 x 的均值 $\bar{x}$ 和 y的均值 $\bar{y}$
- 定义中心化变量：$a_i = x_i - \bar{x}, b_i = y_i - \bar{y}$

此时，每个数据点可表示为二维平面上的一个向量 $(a_i, b_i)$，

- **正协方差**：大多数向量落在第一象限或第三象限，此时向量整体倾向于 “向右上方” 或 “向左下方” 分布，呈现**同向趋势**
- **负协方差**：大多数向量落在第二象限或第四象限，此时向量整体倾向于 “向左上方” 或 “向右下方” 分布，呈现**反向趋势**
- **零协方差**：向量在四个象限中均匀分布，或对称分布于坐标轴两侧，整体无明显同向或反向趋势，即**线性无关**

![[1755366384294.png]]

##### 1.3 布拉瓦茨基 - 皮尔逊相关系数（Bravais-Pearson-Korrelationskoefffzient）

![[1755366603695.png]]
**取值范围**：$-1 \leq r_{xy} \leq 1$

- 是无量纲的量，不再依赖于x或y：

    - $r_{xy} > 0$：**正相关**，存在同向的线性关系，数据点 $(x_i, y_i)$ 倾向于分布在具有正斜率的直线附近
    - $r_{xy} < 0$：**负相关**，存在反向的线性关系，数据点$(x_i, y_i)$倾向于分布在具有负斜率的直线附近
    - $r_{xy} = 0$：**无相关**，不相关，不存在线性关系

**相关性质：**(Eigenschaften des Korrelationskoefffzienten)

- 主要衡量线性关系的**强度**
- **线性变换下，相关系数的绝对值保持不变**
- 具有对称性：$r_{xy} = r_{yx}$
- 正相关意味着：“X越大，平均而言Y也越大”
- 若点恰好位于具有正（负）斜率的直线上，相关系数为 $+1$（$-1$）—— 与该直线的斜率无关（斜率为0或无穷大时除外）
- “相关系数\(= 0\)” 意味着 “没有线性关系”，**但不意味着（变量）独立！（见下方例子）**
- **相关系数（和协方差）对异常值敏感**

![[1755367038524.png]]
当数据**存在非线性关系时**，**即便相关系数数值接近**（此处都为\(-0.06\)），也**无法反映出这些非线性的关联模式，从而体现出该相关系数在捕捉非线性关系上的局限性**

##### 1.4. 线性变换

- **对于精确的线性关系**，有： $r_{xy} = +1$ 或 $-1$ ⟺ $y = ax + b$，其中 $a > 0$ 或 $a < 0$
- 线性变换 $\tilde{x} = a_1x + b_1$，$\tilde{y} = a_2y + b_2$$(a_1, a_2 \neq 0$）： 
	- $r_{xy}$ 是 x 和 y 之间的相关系数
	- $r_{\tilde{x}\tilde{y}}$ 是 $\tilde{x}$ 和 $\tilde{y}$ 之间的相关系数
	- 可得： $r_{\tilde{x}\tilde{y}} = r_{xy}$ ⟺ $a_1$、$a_2$ 符号相同； $r_{\tilde{x}\tilde{y}} = -r_{xy}$ ⟺ $a_1$、$a_2$ 符号不同。

#### 2. 多变量关系展示（Darstellung multivariater Zusammenhänge）

当有两个以上特征时，协方差和相关系数通常以矩阵的形式呈现，在主对角线上，是每个特征与自身的样本协方差或相关系数，也就是各自的样本方差或1。

![[1755367432749.png]]
![[1755367579124.png]]
#### 3. 随机变量的协方差与皮尔逊相关系数（Kovarianzen und Korrelationen）

两个随机变量X、Y的协方差 $\text{Cov}(X, Y)$ 以及**相关系数** $\rho(X, Y)$，是用于衡量随机变量X和Y之间线性相关性的**强度和方向的度量**：

协方差 $\text{Cov}(X, Y)$ 的定义为：

	$\text{Cov}(X, Y) = E\left[(X - E(X))(Y - E(Y))\right]$

而相关系数 $\rho(X, Y)$ 的定义为：

	$\rho(X, Y) = \frac{\text{Cov}(X, Y)}{\sqrt{\text{Var}(X)}\sqrt{\text{Var}(Y)}}$

**Cov(X,Y) = Var(X)**

- 方向上，正值表示正相关（一个变量增大，另一个倾向增大），负值表示负相关（一个变量增大，另一个倾向减小）。
- 强度上，**其绝对值越接近 1，线性相关越强；越接近 0，线性相关越弱**（取值范围为 - 1 到 1）。
- 因经过标准化处理，不受变量量纲影响，可用于不同变量对之间相关强度的比较。

#### 4. 协方差的平移定理（Der Verschiebungssatz für die Kovarianz）

  Cov(X,Y) = E(XY)−E(X)E(Y)

#### 5. 不相关性（Unkorreliertheit）-- 类似独立

若X和Y满足 $\text{Cov}(X, Y) = 0$ 或 $\rho(X, Y) = 0$，则称 X 和 Y 不相关，即满足：$E(XY) = E(X) \cdot E(Y)$

-- **根据平移定理公式简单推论**

注意：独立性可推出不相关性，但反之通常不成立！

若 $\rho(X, Y) > 0$，则X和Y正相关；若 $\rho(X, Y) < 0$，则X和Y负相关

例子：

- Z1 = X + Y
- Z2 = X - Y
- Z1Z2 = $X^2 - Y^2$
- E(Z1Z2) = E($X^2$) - E($Y^2$) 
- 因为是伯努利分布，所以E(Z1Z2) = E(X) - E(Y)

![[1755372370664.png]]

例子说明，两个**随机变量不独立**（f(z1,z2) != f(z1)f(z2))，但是，计算协方差为0，说明**不相关不能推导出独立**。

性质：

如果相关系数的绝对值 = 1 ===》 当且仅当X和Y之间存在完全线性依赖关系，即：

![[1755372721729.png]]
#### 6. 线性变换（Lineare Transformationen）

![[1755372775785.png]]


#### 7. 随机变量之和的方差（Varianz der Summe zweier ZVn）

![[1755372877686.png]]
#### 8. 二元正态分布

![[1755373010438.png]]
![[1755373037867.png]]
#### 9. 其他相关性度量（Alternative Zusammenhangsmaße）

##### 9.1 斯皮尔曼秩相关系数（Spearman-/Rang-Korrelationskoefffzient）

**秩次”（英文为 “rank”）是指将一组数据按照从小到大（或从大到小）的顺序排列后，每个数据所对应的位置序号。**

比如，有一组数据：5、2、8、3。将其从小到大排序为2、3、5、8，那么数据2的秩次是1，3的秩次是2，5的秩次是3，8的秩次是4。

**示例**：

- 无相同值时： 原始数据\(X_i\)：\(2.3\)、\(7.1\)、\(1.0\)、\(2.1\) 对应的秩次\(R(X_i)\)：3、4、1、2
    
- 有相同值时： 原始数据\(X_i\)：\(2.3\)、\(7.1\)、\(1.0\)、\(2.1\)、\(2.3\) 对应的秩次\(R(X_i)\)：\(3.5\)、5、1、2、\(3.5\) （其中两个\(2.3\)的平均秩次为\(\frac{3 + 4}{2} = 3.5\)）

![[1755373539757.png]]

![[1755373494139.png]]
- 若 $\rho_{\text{Spearman}} > 0$，表明存在**同向的单调关系**：趋势为X值大时Y值也倾向于大，X值小时Y值也倾向于小
- 若 $\rho_{\text{Spearman}} < 0$，表明存在**反向的单调关系**：趋势为X值大时Y值倾向于小，X值小时Y值倾向于大。
- 若 $\rho_{\text{Spearman}} \approx 0$，表明**不存在单调关系**

**斯皮尔曼系数的简便计算公式**：

![[1755373793711.png]]

##### 9.2 单调变换（Monotone Transformationen）

- 设 $\tilde{X} = f(X)$，其中 $f$ 是严格单调函数；$\tilde{Y} = h(Y)$，其中 $h$ 是严格单调函数：
- 若 $f$ 和 $h$ **均为单调递增** 或 **均为单调递减**：$\rho_{\text{Spearman}}(\tilde{X}, \tilde{Y}) = \rho_{\text{Spearman}}(X, Y)$
- 若 $f$ 和 $h$ **并非同时递增或同时递减**（即一个递增、一个递减），$\rho_{\text{Spearman}}(\tilde{X}, \tilde{Y}) = -\rho_{\text{Spearman}}(X, Y)$

##### 9.3 配对比较度量：肯德尔 tau 系数（Paarvergleichsmaße: Kendall’s Tau）

考虑观测值对 $(X_i, Y_i)$ 和 $(X_j, Y_j)$：

- **协和对**：若 $X_i < X_j$ 且 $Y_i < Y_j$，或 $X_i > X_j$ 且 $Y_i > Y_j$，即X值与Y值的排序一致。
- **不协和对**：若 $X_i < X_j$ 且 $Y_i > Y_j$，或 $X_i > X_j$且 $Y_i < Y_j$，即X值与Y值的排序相反。

其中：
- $n_c$：协和对的数量
- $n_d$：不协和对的数量

总共有 $n(n-1)/2$ 种可能的配对。

**肯德尔 tau 系数定义为**：$\tau_{\text{Kendall}} = \frac{n_c - n_d}{n(n-1)/2}$

##### 9.4 距离协方差与距离相关系数(Distanzkovarianz & Distanzkorrelation)

**距离协方差**（Distanzkovarianz）和**距离相关系数**（Distanzkorrelation）是一种现代的**关联性度量方法**，可用于衡量（几乎）任意类型的关系（不仅限于线性或单调关系）。其核心思想是**基于观测值之间（中心化的）距离乘积**，**而非仅依赖于观测值与均值的距离**。

![[1755374498996.png]]


![[1755374528308.png]]


#### 10. 关联度量用于二分变量与顺序 / 度量特征(Zusammenhangsmaße für dichotome und ordinale/metrische Merkmale)


二分变量（dichotomous variable）是一种只能取两个不同值的变量，也被称为二分类变量。这两个值通常代表两种相互对立的类别或状态，比如 “是” 与 “否”“有” 与 “无”“成功” 与 “失败”“患病” 与 “健康” 等。


二分变量Y与至少为顺序尺度的变量X。

示例：

- 医学领域：诊断测试X：生物标志物（如血液中的物质浓度等）或诊断评分Y：患病 vs. 健康；痊愈 vs. 死亡；等等……
    
- 营销领域：X：客户特征（例如，与该客户的历史销售额）Y：购买决策是 / 否；合同续约是 / 否；等等……
    
- 信用评分等：X：1.5 年内是否有信贷机构（Schufa）的违约记录

##### 10.1 敏感度和特异性（Sensitivität und Spezifftät）

**设定：**  

▶ $Y \in \{0, 1\}$ 为二分变量（**目标变量**）  
▶ X 至少为序数尺度（**影响变量**）$Y = 1 \iff$ “阳性” 情况（例如 “患病”“信贷违约”“终止合同”……）$Y = 0 \iff$ “阴性” 情况（例如 “健康”“还款”“续约”……）

**目标：**  

仅基于 $x_i$ 和阈值 c 进行预测 / 诊断 $\hat{y}_i$：$\hat{y}_i = 1 \iff x_i \geq c$

**!!! 就是无法直接预测 Y，而是用过 X 的采集样本以及一个门限 c ，来 “间接“估计 Y**

**问题：**  

- 如何确定合适的阈值c？  
- 特征 x 用于评估 y 的整体效果如何？

由于我们用**单一阈值 c 对连续或有序的 x 进行 “非此即彼” 的划分**（要么阳性，要么阴性），必然会出现 “顾此失彼” 的情况

- **门限 c 越大** -> 阳性预测（Y = 1）越少
	- **假阳性减少**：提高了门限，正常的但是指标略高的不再被判定为阳性，所以减少  **-- 好事**
	- **真阳性减少**：一些有问题的阳性，但是指标不是很大，被判定为阴性，所以，真阳性页减少了 **-- 坏事**
- **门限c越小** -> 阴性预测（Y=0）越少
	- **假阴性减少**：由于降低了门限，部分真阳性被判定为阳性（真阳性），所以假阴性减少 **-- 好事**
	- **真阴性减少**：由于降低了门限，部分真阴性样本被判定为阳性（假阳性），所以真阴性减少 **-- 坏事**

**敏感性**：（真阳性率）Sensitivität

- 真正阳性个体中预测为阳性的比例 -- "**患病者中被检测出的比例是多少**"
- $TPR(c) = f(\hat{Y}=1|Y = 1) = f(X \geq c|Y = 1)$ -- 真阳性率

- 真正阴性个体中预测为阳性的比例 -- "**健康者中被误诊断为阳性的比例是多少？**"
- $FPR(c) = f(\hat{Y}=1|Y = 0) = f(X \geq c|Y = 0)$ -- 假阳性率

**特异性：**（假阳性率） Spezifität

- 真正阴性个体中预测为阴性的比例 -- "**健康者中被正确诊断的比例是多少**"
- $TNR(c) = f(\hat{Y}=0|Y = 0) = 1 - f(X \geq c|Y = 0) = 1 - FPR(c)$

**ROC曲线：**

▶ 连接点（$FPR(c)$，$TPR(c)$），即（**1 - 特异性**，**敏感性**）或（“假阳性” 率，“真阳性” 率）  
▶ 覆盖所有可能的阈值 $c \in [x_{(1)}, x_{(n)}]$

存在以下情况：

- 当 $c < x_{(1)}$ 时，检测结果始终为 ”阳性“，即对于所有的 $x_i$ 都有 $\hat{Y}_i = 1$
- 当 $c > x_{(n)}$ 时，检测结果始终为 ”阴性“，即 对于所有的 $x_i$ 都有 $\hat{Y}_i = 0$

它展示了在所有可能的**阈值 c** 下预测的可靠性。

![[1755453646415.png]]

ROC 曲线 x 轴 是特异性（假阳性率），y 轴是敏感性（真阳性率）

ROC 曲线描绘了**不同阈值下**“真阳性率” 与 “假阳性率” 的 trade - off（权衡），曲线越靠左上角，模型整体区分 “健康” 和 “患病” 的能力越强。

对角线是”**随机猜测**“模型下的 真阳性率/假阳性率（几率50%）

**从 “成本权衡” 角度（临床 / 业务场景）**

不同场景对 “假阳性（FPR）” 和 “假阴性（漏诊，即 \(1 -\) 敏感性）” 的 “代价” 定义不同：

- **疾病筛查（怕漏诊）**：更容忍 “假阳性”（后续可二次检查排除），要**提高敏感性**（多抓真患病者），此时应选**较低的 c**（让更多样本被预测为 “阳性”）。

![[1755454316576.png]]



- **罕见病确诊（怕误诊）**：更容忍 “假阴性”，要**提高特异性**（**少把健康人判为患病**），此时应选**较高的 c**（严格限制 “阳性” 预测）。


![[1755454334465.png]]

如果模型结果几乎是对角线，说明 **模型预测与真实结果几乎无关联**，此时模型无任何区分能力

**敏感度和特异度接近0.5**

![[1755454467751.png]]


![[1755454719184.png]]

模型接近对角线时候，有两类情况：

- 完全无关联，敏感度和特异度都在0.5附近
- 对健康识别较好（敏感度好），但是对患病识别很差（特异度低），所以更适合”**宁可漏诊**“，**也不误诊**（**比如某种过度诊断会带来严重心理 / 经济负担的疾病筛查**）


- **敏感性** ：
	- **真阳 / （真阳 + 假阴）**
	- 敏感性高，说明病患群体中被抓出真阳性的多。
- **阳性预测值**（pos. prädiktiver Wert）：--- PPV
	- **真阳 / （真阳 + 假阳）**
	- 阳性预测值高，说明模型预测为阳性的样本中，实际真正为阳性的比例高
- **特异性**：
	- **真阴 / （真阴 + 假阳）**
	- 特异性高，说明健康群体中被正确识别为阴性的多
- **阴性预测值**（neg. prädiktiver Wert）--- NPV
	- **真阴 / （真阴 + 假阴）**
	- 阴性预测值高，说明模型预测为阴性的样本中，实际真正为阴性的比例高

- TP - 真阳
- FP - 假阳
- TN - 真阴
- FN - 假阴

![[1755461185050.png]]![[1755461961297.png]]

**评估ROC曲线的指标 - AUC：**

AUC 对应ROC曲线下面的面积。

	$AUC := \frac{N_c + N_E/2}{N}$

- 一致对的数量  $N_C = |\{(i,j): (x_i > x_j \land y_i > y_j) \lor (x_i < x_j \land y_i < y_j)\}|$
- x 中存在平局的对的数量 $N_E = |\{(i,j): x_i = x_j \land y_i \neq y_j\}|$
- 所有 y 不同的对的数量 $N = |\{(i,j): y_i \neq y_j\}| = h_Y(0)h_Y(1)$

- AUC =  1：模型具有完美区分能力
- AUC 在 0.7 和 1之间，说明模型具有较好的区分能力。在大多数情况下，模型能够较为准确地区分正类和负类样本，不过仍存在一定比例的错误分类情况，但整体性能是比较不错的。
- AUC在 0.5 和 0.7 之间：模型的区分能力一般。此时模型的预测效果和随机猜测的表现相比，只是略好一些，对于正类和负类样本的区分不是很有效，存在较多的错误分类。
- AUC = 0.5 ： 意味着模型的预测能力和随机猜测没有区别
- AUC 在 0 到 0.5 之间： 模型的预测能力比随机猜测还差，而且存在反向的区分情况
- AUC == 0 ： 表示模型具有完全反向的区分能力。对于所有的正负样本对，模型都错误地将负样本的预测得分（或概率）高于正样本的预测得分（或概率），完全颠倒了正类和负类样本的区分。


#### 11. 脉络

##### 11.1  **两个变量的线性关联度量**

- **协方差**：
	- **核心**：衡量两个度量型变量**线性关系的方向和强度**
	- **局限**：受量纲影响，无法直接比较不同变量对的关联强度，仅反映线性关系。
- **皮尔逊系数**：
	- **定位**：协方差的 “标准化” 延伸
	- **突破**：无量纲，取值范围 [-1,1]，可直接比较不同变量对的线性关联强度；核心仍是衡量线性关系
##### 11.2 **协方差的性质与扩展**

- **协方差平移定理**：
	- **本质**：协方差的简化计算公式，即 $\text{Cov}(X,Y) = E(XY) - E(X)E(Y)$
	- **作用**：将协方差与变量的期望直接关联，简化理论推导（如不相关性的判定）
- **不相关性**：
	- **定义**：若 $\text{Cov}(X,Y)=0$ 或皮尔逊系数 $\rho=0$，则变量不相关，此时由平移定理得 $E(XY)=E(X)E(Y)$
	- **关系**：独立性→不相关性（反之不成立），即不相关仅表示无线性关联，可能存在非线性关系
- **线性变换对关联度量的影响**：
	- **对协方差**：受系数乘积影响，$\text{Cov}(\tilde{X},\tilde{Y})=a_1a_2\text{Cov}(X,Y)$
	- **对皮尔逊系数**：仅受系数符号影响（同号则系数不变，异号则取反），与平移量无关，体现其对线性变换的稳健性
##### 11.3 **随机变量的方差与关联**

- **公式**：$\text{Var}(X+Y) = \text{Var}(X) + \text{Var}(Y) + 2\text{Cov}(X,Y)$
- **意义**：揭示**变量间的协方差对 “和的离散程度” 的影响** —— 若正相关，和的方差增大；负相关则减小，体现关联对整体变异的作用
##### 11.4 **超越线性：单调关系与排序关联**

- **斯皮尔曼秩相关系数（Spearman Rank Correlation）**
    - **定位**：基于变量 “秩次”（排序后的位置）的关联度量，公式为对秩次计算皮尔逊系数。
    - **适用**：捕捉**单调关系**（线性或非线性的单调趋势），对异常值更稳健。
- **单调变换对斯皮尔曼系数的影响**
    - **规律**：若变量经严格单调函数变换（如$\tilde{X}=f(X)$，$f$ 递增或递减），则斯皮尔曼系数的绝对值不变（符号由变换方向决定）。
    - **原因**：**单调变换不改变变量的秩次排序，因此秩相关关系不变**。
- **肯德尔 tau 系数（Kendall's Tau）**
    - **定位**：通过比较 “观测对的排序一致性” 衡量关联，公式为 $\tau = \frac{n_c - n_d}{n(n-1)/2}$（$n_c$为协和对，$n_d$为不协和对）。
    - **特点**：直接基于排序逻辑，对 tied 值（相同值）更敏感，同样适用于单调关系。
##### 11.5 **突破线性与单调：任意关系度量**

- **距离协方差（Distance Covariance）**
    - **定位**：基于 “观测值之间的距离” 衡量关联，突破线性和单调关系的限制，可捕捉**任意类型关系**（如非线性、非单调）。
    - **核心**：通过中心化距离矩阵的乘积计算，弥补传统协方差和秩相关在复杂关系上的局限。

### **脉络总结**

- **基础层**：**协方差**→**皮尔逊系数**（**线性关系**，**有量纲**→无量纲**）。**
- **性质层**：**平移定理**（协方差计算简化）→**不相关性**（线性无关的判定）→**线性变换与和的方差**（关联的数学性质）。
- **扩展层**：**斯皮尔曼系数**→**肯德尔 tau 系数**（从线性到单调关系，基于秩次 / 排序）。
- **进阶层**：**距离协方差**（突破线性和单调，捕捉任意关系）。

#### 12. 简答题

1. **协方差的正负分别表示什么含义？为什么协方差的绝对值大小能反映两个变量线性关联的强度？**

	- 协方差用于衡量两个度量特征之间**线性关系**的**强度和方向**，公式为：xxxx
	- **正协方差**：两个变量呈正向线性相关，即一个变量大于均值时，另一个也倾向于大于均值（反之亦然）
	- **负协方差**：两个变量呈反向线性相关，即一个变量大于均值时，另一个倾向于小于均值（反之亦然）

2. **皮尔逊相关系数与协方差相比，有什么优势？其取值范围和不同取值分别代表什么意义？**

	- 皮尔逊相关系数的优势是**无量纲**，不受变量量纲影响，可直接比较不同变量对的相关强度
	- **取值范围**：(-1, 1)
	- **意义**：绝对值越接近 1，线性相关越强；**0 表示无线性关系，但不排除非线性关系**

3. **若两个变量的皮尔逊相关系数为 0，能否说明这两个变量完全无关？为什么？**

	- 不能。皮尔逊相关系数为 0 仅表示变量间**不存在线性关系**，但可能存在非线性关系（如二次关系）

4. **为什么说相关系数对异常值敏感？**

	- 相关系数（如皮尔逊相关系数）对异常值敏感，核心原因是其计算依赖于变量的具体数值（尤其是偏离均值的程度），异常值会显著扭曲变量间线性关系的估计

5. 对于多变量的情况，协方差矩阵和相关系数矩阵的主对角线元素分别代表什么？这体现了它们的什么特性？
6. **随机变量的不相关性和独立性有什么关系？**

	- **关系**：独立性可推出不相关性（**若独立，则协方差为 0，即不相关**），但不相关性**不能推出**独立性。

7. **斯皮尔曼秩相关系数与皮尔逊相关系数的适用场景有何不同？为什么斯皮尔曼秩相关系数能反映变量间的单调关系？**

	- **适用场景**：皮尔逊系数适用于**线性关系**，斯皮尔曼系数适用于**单调关系**（无论线性与否），且**对异常值更稳健**。
	- **原因**：斯皮尔曼系数基于变量的 “秩次”（排序后的位置序号）计算，**而非原始值**。单调关系中变量的秩次始终保持同向或反向趋势，因此秩次的相关性能捕捉这种趋势。

8. **在计算斯皮尔曼秩相关系数时，当数据存在相同值时，如何处理其秩次？这样处理的原因是什么？**

	- **处理方式**：当数据存在相同值时，将这些相同值所处位置的秩次取算术平均值作为它们的共同秩次。例如，若数据中两个值并列第 3 和第 4 位，则它们的秩次均为（3+4）/2 = 3.5。
	    
	- **原因**：这种处理方式能保持秩次的连贯性和公平性，避免因相同值的秩次随意分配（如强制排序）而扭曲变量间的实际排序关系，确保斯皮尔曼秩相关系数能准确反映变量间的单调关联趋势。

9. **肯德尔 tau 系数是通过什么方式衡量变量间关联的？协和对和不协和对的定义分别是什么？**

	- **衡量方式**：肯德尔 tau 系数通过比较所有观测值对的排序一致性来衡量变量间关联
	- 协和对$(n_c$）：若 $X_i < X_j$且$Y_i < Y_j$，或$X_i > X_j$且$Y_i > Y_j$，即两变量排序方向一致
	- 不协和对（$n_d$）：若$X_i < X_j$且$Y_i > Y_j$，或$X_i > X_j$且$Y_i < Y_j$，即两变量排序方向相反

10. **距离协方差与距离相关系数相比传统的协方差和相关系数，在衡量变量关系上有什么突破？**

	- 传统协方差和相关系数仅能捕捉**线性关系**，对非线性、非单调关系不敏感；
	- 而距离协方差与距离相关系数基于**观测值之间的中心化距离乘积**计算，突破了对线性关系的依赖，可衡量**几乎任意类型的关系**（包括非线性、非单调关系），能更全面地反映变量间的关联，弥补了传统方法在捕捉复杂关系上的局限性。

11. **敏感度（真阳性率）和特异性（真阴性率）的定义分别是什么？它们与阈值 c 的大小有什么关系？**

	- **敏感度**（TPR）：真正阳性个体中被预测为阳性的比例
	- **特异性**（TNR）：真正阴性个体中被预测为阴性的比例

12. **在疾病筛查和罕见病确诊场景中，对阈值 c 的选择有何不同？为什么会有这样的差异？**

	- 疾病筛查：选**较低阈值 c**。为减少漏诊（提高敏感度），容忍更多假阳性（可后续排除），优先捕获潜在患者。
	- 罕见病确诊：选**较高阈值 c**。为减少误诊（提高特异性），严格限制阳性判定，避免健康人被误判，降低不必要负担。

13. **ROC 曲线是如何绘制的？其形状能反映模型的什么能力？对角线代表什么意义？**

	- **横轴**：假阳性率（FPR，即 1 - 特异性）
	- **纵轴**：真阳性率（TPR，即敏感度）
	- **形状意义**：曲线越靠近左上角，模型区分正负类的能力越强；对角线代表随机猜测（无区分能力）；曲线若接近右下角，则模型性能差于随机猜测。

14. **AUC 指标的含义是什么？不同范围的 AUC 值分别说明模型具有怎样的区分能力？**

	- AUC 是 ROC 曲线下的面积，**衡量模型在所有阈值下的整体区分能力**
	- AUC=1：完美区分能力。
	- 0.7~1：较好区分能力，多数情况下能准确分类。
	- 0.5~0.7：区分能力一般，仅略好于随机猜测。
	- 0.5：与随机猜测无差异。
	- 0~0.5：差于随机猜测，存在反向区分。
	- AUC=0：完全反向区分。

15. **阳性预测值（PPV）和阴性预测值（NPV）的定义是什么？它们与敏感度和特异性有何区别？**

- **定义**：

    - 阳性预测值（PPV）：模型预测为阳性的样本中，实际为阳性的比例，即 $\text{PPV} = \frac{\text{真阳性（TP）}}{\text{真阳性（TP）+ 假阳性（FP）}}$
    - 阴性预测值（NPV）：模型预测为阴性的样本中，实际为阴性的比例，即 $\text{NPV} = \frac{\text{真阴性（TN）}}{\text{真阴性（TN）+ 假阴性（FN）}}$
    
- **与敏感度和特异性的区别**：
    
    - **PPV** 和 **NPV** 基于 “预测结果”（预测阳性 / 阴性群体），**衡量预测结果的可信度**
    - 敏感度（TPR，基于真实阳性群体）和特异性（TNR，基于真实阴性群体），**衡量模型对真实类别的识别能力** 
    - 前者关注 “**预测准不准**”，后者关注 “**真实类别抓没抓住**”