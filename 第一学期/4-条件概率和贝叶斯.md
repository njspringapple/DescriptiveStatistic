概率：基础与定义  
概率：概念形成与解释  
拉普拉斯概率  
柯尔莫哥洛夫公理  
### 条件概率  

定义：对于事件 A、B⊆Ω，且 P (B) > 0 时，在 B 发生的条件下 A 发生的条件概率为

**P(A交B) / P(B)**

- 可加性：**若A1和A2互斥**，则 P((A1 并 A2)|B) = P(A1|B) + P(A2|B))
- **多重条件化**⟹基于条件的交集进行条件化 ：P((A∣B)∣C)=P(A∣(B∩C))

- **乘法规则**：P(A1​∩A2​∩⋯∩An​) = P(A1​)⋅P(A2​∣A1​)⋅P(A3​∣A1​∩A2​)⋅⋯⋅P(An​∣A1​∩⋯∩An−1​)
- **非正式标记法**：P(A1​,A2​):=P(A1​∩A2​)
- P(A1,A2,A3) = P(A1)P(A2|A1)P(A3|A1,A2).....

- **全概率公式：**
	- 互斥分割：若B1，B2，...，Bn 两两互斥，有Bi 交 Bj = 空集，且 B1 并 B2 ... 并 Bn = 样本空间，则他们构成了样本空间的一个互斥分割
	- 如果B1，。。。，Bn是样本空间的一个互斥分割，A 是任意事件，有 P(A) = ∑i=1n​P(A∣Bi​)⋅P(Bi​)   -- 全概率公式的核心思想是**将复杂事件A的概率分解为多个简单情形的概率之和**  
	- P(A) = P(A|B)P(B) + P(A|B的补集)P(B的补集)
### 随机独立性  

- 两个事件A，B是随机独立的，当且仅当事件A的概率不会因事件B的发生而改变：

P(A|B) = P(A) 或者 P(B|A) = P(B)

因为 P(A|B) = P(A 交 B) / P（B），所以，**P（A 交 B） = P(A) P(B)**, 记法：  
A⊥B⟺P(A∩B)=P(A)⋅P(B) 

推广到**对立**事件：

- A⊥B⟺A补 ⊥B
- A⊥B⟺A⊥B补
- A⊥B⟺A补⊥B补

对立事件的独立性则表明：**若两个事件独立，那么其中一个事件是否发生，与另一个事件是否不发生也互不影响**

**如果 P(A∩B) 不等于 P(A)⋅P(B)，说明A和B是相互依赖的**

**多个事件的随机独立性**：如果A1，。。。An是随机独立的，当且仅当 I 属于 {1，2，。。。，n}，I = {i1，i2，。。。，ik}，都有 P（Ai1，Ai2，。。。，Aik） = P（Ai1）P（Ai2）。。。P（Aik）

多个事件的独立性要求**所有可能的子集组合**都满足 “交事件的概率等于各事件概率的乘积”，这比仅满足 “两两独立”（即任意两个事件的交概率等于概率乘积）的条件更严格，

**例如 三个事件ABC，若仅仅满足两两相交概率等于概率乘积，不满足三个相交的概率乘积，这三个事件不能称为多个事件的独立。**


**条件独立性**：设C是任意满足P(C) > 0的事件。若两个事件A和B满足：P（A 交 B | C） = P（A | C）P（B | C），则称A和B在给定条件C下是条件独立的，记法：(A⊥B)∣C ⟺P(A∩B∣C)=P(A∣C)⋅P(B∣C)


**条件独立性 和 无条件独立性不能互相转化**

- 例如，“雨天（C）” 时，“带伞（A）” 和 “迟到（B）” 可能条件独立（带伞与否不影响迟到概率），但在无条件情况下，两者可能相关（雨天更可能带伞，也更可能迟到）。

### 贝叶斯定理

**P(A∣B)P(B)=P(B∣A)P(A)**

贝叶斯定理的核心是通过两个条件概率（\(P(A|B)\)和\(P(B|A)\)）与边缘概率（\(P(A)\)和\(P(B)\)）的关系，实现概率的 “逆推”

- P(Bi) 称为**先验概率**        即未观察到事件 A 时，对 \(B_i\) 成立的**信念程度**
- P(A|B_i) 称为**事件 A 的似然度**          表示在假设 \(B_i\) 成立的前提下，观察到事件 A 的合理性（即假设为真时，观察结果出现的概率）
- P(B_i|A)称为**后验概率**      基于事件 A 的观察结果，假设 B_i 的概率从先验概率 P(B_i) 更新为 P(B_i|A)（即观察到新信息后，对假设合理性的修正）。

由此，贝叶斯定理提供了一种 “更新规则”：  
**通过观察到的数据 A，如何修正对先验假设 \(B_i\) 的合理性判断？**


贝叶斯定理的核心价值在于**将先验知识与新观察结合，实现对假设概率的动态更新**

- **先验概率** \(P(B_i)\) 可表示 “人群中患病（\(B_1\)）或不患病（\(B_2\)）的基础概率”；
- **似然度** \(P(A|B_i)\) 表示 “患病时检测呈阳性（A）的概率” 和 “不患病时检测呈阳性的概率”；
- **后验概率** \(P(B_i|A)\) 则是 “检测呈阳性时，实际患病或不患病的概率”—— 这正是临床决策中更关注的结果，体现了新观察（阳性结果）对先验信念（基础患病率）的修正。


- 先验概率：**是我们在获得新证据前对某事的初始判断**。就像你在看天气预报前，凭经验认为明天下雨的可能性有30%，这是基于你的已有知识和经验做出的初步估计。
- **似然度**：衡量的是当某种情况为真时，我们观察到的证据出现的概率。比如说，如果明天真的会下雨，那么今天看到乌云密布的可能性有多大？
- **后验概率**：是在看到新证据后，对初始判断的更新结果。继续用天气的例子：当你看到天上乌云密布后，你会根据这个新信息调整对明天下雨的预期

P(A|B) = [P(A) × P(B|A)] / P(B)

其中:

- P(A|B) 是后验概率 - 观察到证据B后，事件A的概率
- P(A) 是先验概率 - 在观察证据前，对事件A的初始估计
- P(B|A) 是似然度 - 若A为真，观察到B的概率
- P(B) 是证据概率 - 观察到B的总体概率


这使得我们能够在已知观察数据 A 和概率模型 \(P(A|B_i)\) 的情况下，**对无法直接观察的现象 / 模型假设 \(B_i\) 的合理性进行推断**。

贝叶斯定理的核心意义在于突破了 “**从原因推结果” 的局限**，实现了 “**从结果反推原因**” 的逻辑跃迁

K-某人患病  T-疾病监测结果为阳性

- **灵敏度**：P(T|K)  患者阳性概率 **-- 特殊的似然**
- **特异度**：P(T补|K补) 健康人时候阴性概率        
- **患病率**：P（K） **基础患病概率，先验概率**

在医学诊断中，灵敏度和特异度是检测方法本身的固有属性（衡量检测准确性），而患病率反映疾病在人群中的普遍程度。**但临床决策更关注 “检测结果为阳性时，患者真的患病的概率”（阳性预测值）** 和 “**检测结果为阴性时，患者真的健康的概率”（阴性预测值）**。这些关键指标需通过贝叶斯定理计算：

- **阳性预测**：P(K|T) = P(T|K)P(K) / (P(T|K)P(K) + P(T|K)P(K补))
- **阴性预测值**：P(K补|T补) = 。。。。

对于**罕见病（低患病率）**，即使检测灵敏度和特异度很高，阳性预测值也可能较低（因假阳性占比相对较高），这体现了贝叶斯定理在解读检测结果时的重要性。


P(患病 | 检测阳性) = 

P(患病) x P（检测阳性 | 患病）/ P（检测阳性）= 
（患病率 x 灵敏度） / P（检测阳性 | 患病）x P（患病） + P（检测阳性 | 未患病） x P（未患病）= 
 （**患病率** x 灵敏度）/ （（**患病率** x 灵敏度）+ （（1 - 特异度） x （1 - **患病率**）） 


赔率：O（A） = P（A）/ （1 - P（A））

**赔率常用于赌博、统计学等领域，它表示 “事件发生的概率” 与 “事件不发生的概率” 之比**

赔率的优势在于能更直观地体现**事件发生与不发生的相对可能性**，尤其在比较不同事件的风险或收益时更为方便
、

 赔率引入贝叶斯：

γ（B|A) = γ（B) 乘以 （P（A|B) / P(A|B补)） **后验赔率 = 先验赔率 × 似然比**，似然比它衡量了数据D对假设H的**支持强度**

假如 灵敏度P(T|K) = 0.8     特异性P(T补|K补) = 0.99 ， 患病率P（K）= 0.001，

先验赔率 O（K）= 0.001/0.999 = 1：999

似然比 = P（T|K）/ P（T|K补）= 0.8/0.01 = 80

后验概率 = 1/999 乘以 80 = 1：12，意味着13个阳性检测中只有1个真正患者


 **在解读概率时，不能忽视事件本身的先验概率（基础发生率）**



